{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = [\"а\",\"б\",\"в\",\"г\",\"д\",\"е\",\"ё\",\"ж\",\"з\",\"и\",\"й\",\"к\",\"л\",\"м\",\"н\",\"о\",\n",
    "            \"п\",\"р\",\"с\",\"т\",\"у\",\"ф\",\"х\",\"ц\",\"ч\",\"ш\",\"щ\",\"ъ\",\"ы\",\"ь\",\"э\",\"ю\",\"я\"]\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['а',\n",
       "  'б',\n",
       "  'в',\n",
       "  'г',\n",
       "  'д',\n",
       "  'е',\n",
       "  'ё',\n",
       "  'ж',\n",
       "  'з',\n",
       "  'и',\n",
       "  'й',\n",
       "  'к',\n",
       "  'л',\n",
       "  'м',\n",
       "  'н',\n",
       "  'о',\n",
       "  'п',\n",
       "  'р',\n",
       "  'с',\n",
       "  'т',\n",
       "  'у',\n",
       "  'ф',\n",
       "  'х',\n",
       "  'ц',\n",
       "  'ч',\n",
       "  'ш',\n",
       "  'щ',\n",
       "  'ъ',\n",
       "  'ы',\n",
       "  'ь',\n",
       "  'э',\n",
       "  'ю',\n",
       "  'я',\n",
       "  'А',\n",
       "  'Б',\n",
       "  'В',\n",
       "  'Г',\n",
       "  'Д',\n",
       "  'Е',\n",
       "  'Ё',\n",
       "  'Ж',\n",
       "  'З',\n",
       "  'И',\n",
       "  'Й',\n",
       "  'К',\n",
       "  'Л',\n",
       "  'М',\n",
       "  'Н',\n",
       "  'О',\n",
       "  'П',\n",
       "  'Р',\n",
       "  'С',\n",
       "  'Т',\n",
       "  'У',\n",
       "  'Ф',\n",
       "  'Х',\n",
       "  'Ц',\n",
       "  'Ч',\n",
       "  'Ш',\n",
       "  'Щ',\n",
       "  'Ъ',\n",
       "  'Ы',\n",
       "  'Ь',\n",
       "  'Э',\n",
       "  'Ю',\n",
       "  'Я'],\n",
       " 66)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = alphabet + [x.upper() for x in alphabet]\n",
    "alphabet, len(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mv  -v ~/Downloads/* ~/Videos/\n",
    "\n",
    "It will move all the files and folders from Downloads folder to Videos folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_20_00',\n",
       " '01_14_00',\n",
       " '01_04_00',\n",
       " '01_30_00',\n",
       " '01_10_00',\n",
       " '01_24_00',\n",
       " '01_00_00',\n",
       " '01_11_00',\n",
       " '01_25_00',\n",
       " '01_01_00',\n",
       " '01_21_00',\n",
       " '01_15_00',\n",
       " '01_05_00',\n",
       " '01_31_00',\n",
       " '00_24_00',\n",
       " '00_10_00',\n",
       " '00_00_00',\n",
       " '00_14_00',\n",
       " '00_20_00',\n",
       " '00_30_00',\n",
       " '00_04_00',\n",
       " '00_15_00',\n",
       " '00_21_00',\n",
       " '00_31_00',\n",
       " '00_05_00',\n",
       " '00_25_00',\n",
       " '00_11_00',\n",
       " '00_01_00',\n",
       " '01_18_00',\n",
       " '00_16_00',\n",
       " '00_22_00',\n",
       " '00_32_00',\n",
       " '00_06_00',\n",
       " '01_08_00',\n",
       " '01_28_00',\n",
       " '00_26_00',\n",
       " '00_12_00',\n",
       " '00_02_00',\n",
       " '01_29_00',\n",
       " '00_27_00',\n",
       " '00_13_00',\n",
       " '00_03_00',\n",
       " '01_19_00',\n",
       " '00_17_00',\n",
       " '00_23_00',\n",
       " '00_07_00',\n",
       " '01_09_00',\n",
       " '01_12_00',\n",
       " '00_28_00',\n",
       " '01_26_00',\n",
       " '01_02_00',\n",
       " '01_22_00',\n",
       " '00_18_00',\n",
       " '01_16_00',\n",
       " '01_06_00',\n",
       " '00_08_00',\n",
       " '01_32_00',\n",
       " '01_23_00',\n",
       " '00_19_00',\n",
       " '01_17_00',\n",
       " '01_07_00',\n",
       " '00_09_00',\n",
       " '01_13_00',\n",
       " '00_29_00',\n",
       " '01_27_00',\n",
       " '01_03_00']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = 'data/archive/00_00_00/00_00_00'\n",
    "pths = os.listdir('data/archive')\n",
    "pths.remove('.DS_Store')\n",
    "pths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mv  -v data/archive/01_20_00/01_20_00/* data/archive/01_20_00/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "f\"mv  -v {paths[i]}/* {paths[0][:paths[0].rfind('/')]}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/archive/01_20_00/01_20_00',\n",
       " 'data/archive/01_14_00/01_14_00',\n",
       " 'data/archive/01_04_00/01_04_00',\n",
       " 'data/archive/01_30_00/01_30_00',\n",
       " 'data/archive/01_10_00/01_10_00',\n",
       " 'data/archive/01_24_00/01_24_00',\n",
       " 'data/archive/01_00_00/01_00_00',\n",
       " 'data/archive/01_11_00/01_11_00',\n",
       " 'data/archive/01_25_00/01_25_00',\n",
       " 'data/archive/01_01_00/01_01_00',\n",
       " 'data/archive/01_21_00/01_21_00',\n",
       " 'data/archive/01_15_00/01_15_00',\n",
       " 'data/archive/01_05_00/01_05_00',\n",
       " 'data/archive/01_31_00/01_31_00',\n",
       " 'data/archive/00_24_00/00_24_00',\n",
       " 'data/archive/00_10_00/00_10_00',\n",
       " 'data/archive/00_00_00/00_00_00',\n",
       " 'data/archive/00_14_00/00_14_00',\n",
       " 'data/archive/00_20_00/00_20_00',\n",
       " 'data/archive/00_30_00/00_30_00',\n",
       " 'data/archive/00_04_00/00_04_00',\n",
       " 'data/archive/00_15_00/00_15_00',\n",
       " 'data/archive/00_21_00/00_21_00',\n",
       " 'data/archive/00_31_00/00_31_00',\n",
       " 'data/archive/00_05_00/00_05_00',\n",
       " 'data/archive/00_25_00/00_25_00',\n",
       " 'data/archive/00_11_00/00_11_00',\n",
       " 'data/archive/00_01_00/00_01_00',\n",
       " 'data/archive/01_18_00/01_18_00',\n",
       " 'data/archive/00_16_00/00_16_00',\n",
       " 'data/archive/00_22_00/00_22_00',\n",
       " 'data/archive/00_32_00/00_32_00',\n",
       " 'data/archive/00_06_00/00_06_00',\n",
       " 'data/archive/01_08_00/01_08_00',\n",
       " 'data/archive/01_28_00/01_28_00',\n",
       " 'data/archive/00_26_00/00_26_00',\n",
       " 'data/archive/00_12_00/00_12_00',\n",
       " 'data/archive/00_02_00/00_02_00',\n",
       " 'data/archive/01_29_00/01_29_00',\n",
       " 'data/archive/00_27_00/00_27_00',\n",
       " 'data/archive/00_13_00/00_13_00',\n",
       " 'data/archive/00_03_00/00_03_00',\n",
       " 'data/archive/01_19_00/01_19_00',\n",
       " 'data/archive/00_17_00/00_17_00',\n",
       " 'data/archive/00_23_00/00_23_00',\n",
       " 'data/archive/00_07_00/00_07_00',\n",
       " 'data/archive/01_09_00/01_09_00',\n",
       " 'data/archive/01_12_00/01_12_00',\n",
       " 'data/archive/00_28_00/00_28_00',\n",
       " 'data/archive/01_26_00/01_26_00',\n",
       " 'data/archive/01_02_00/01_02_00',\n",
       " 'data/archive/01_22_00/01_22_00',\n",
       " 'data/archive/00_18_00/00_18_00',\n",
       " 'data/archive/01_16_00/01_16_00',\n",
       " 'data/archive/01_06_00/01_06_00',\n",
       " 'data/archive/00_08_00/00_08_00',\n",
       " 'data/archive/01_32_00/01_32_00',\n",
       " 'data/archive/01_23_00/01_23_00',\n",
       " 'data/archive/00_19_00/00_19_00',\n",
       " 'data/archive/01_17_00/01_17_00',\n",
       " 'data/archive/01_07_00/01_07_00',\n",
       " 'data/archive/00_09_00/00_09_00',\n",
       " 'data/archive/01_13_00/01_13_00',\n",
       " 'data/archive/00_29_00/00_29_00',\n",
       " 'data/archive/01_27_00/01_27_00',\n",
       " 'data/archive/01_03_00/01_03_00']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for path in pths:\n",
    "    paths.append('data/archive/'+path+'/'+path)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('move.sh', 'w') as file:\n",
    "    file.write('#!/bin/bash\\n')\n",
    "    for i in range(len(paths)):\n",
    "        file.write(f\"mv  -v {paths[i]}/* {paths[i][:paths[i].rfind('/')]}/\\n\")\n",
    "        file.write(f\"rm -r {paths[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/archive/00_00_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "image = PIL.Image.open(\"/Users/makarbaderko/Downloads/archive/00_00_00/00_00_00/00_00_00_0000.png\")\n",
    "width, height = image.size\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57627 files belonging to 66 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    './data/archive', labels='inferred', label_mode='int',\n",
    "    class_names=None, color_mode='rgb', batch_size=32, image_size=(32,\n",
    "    32), shuffle=False, seed=None, validation_split=None, subset=None,\n",
    "    interpolation='bilinear', follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57627 files belonging to 66 classes.\n",
      "Using 46102 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    './data/archive', labels='inferred', label_mode='int',\n",
    "     color_mode='rgb', batch_size=32, image_size=(32,\n",
    "    32), seed=42, validation_split=0.2, subset='training',\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57627 files belonging to 66 classes.\n",
      "Using 11525 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    './data/archive', labels='inferred', label_mode='int',\n",
    "     color_mode='rgb', batch_size=32, image_size=(32,\n",
    "    32), seed=42, validation_split=0.2, subset='validation',\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_names = alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds.class_names = alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(alphabet)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(32, 32, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7ffdb3cd36a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7ffdb3cd36a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1440/1441 [============================>.] - ETA: 0s - loss: 2.4686 - accuracy: 0.3810WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7ffd95f59ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7ffd95f59ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1441/1441 [==============================] - 29s 19ms/step - loss: 2.4677 - accuracy: 0.3812 - val_loss: 1.1436 - val_accuracy: 0.6803\n",
      "Epoch 2/10\n",
      "1441/1441 [==============================] - 30s 21ms/step - loss: 0.8768 - accuracy: 0.7544 - val_loss: 0.7192 - val_accuracy: 0.7911\n",
      "Epoch 3/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.5996 - accuracy: 0.8265 - val_loss: 0.5946 - val_accuracy: 0.8269\n",
      "Epoch 4/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.4531 - accuracy: 0.8674 - val_loss: 0.4744 - val_accuracy: 0.8587\n",
      "Epoch 5/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.3750 - accuracy: 0.8872 - val_loss: 0.4277 - val_accuracy: 0.8787\n",
      "Epoch 6/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.3168 - accuracy: 0.9031 - val_loss: 0.3680 - val_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.2733 - accuracy: 0.9161 - val_loss: 0.4226 - val_accuracy: 0.8778\n",
      "Epoch 8/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.2400 - accuracy: 0.9254 - val_loss: 0.3447 - val_accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "1441/1441 [==============================] - 34s 23ms/step - loss: 0.2146 - accuracy: 0.9329 - val_loss: 0.3448 - val_accuracy: 0.9040\n",
      "Epoch 10/10\n",
      "1441/1441 [==============================] - 31s 22ms/step - loss: 0.1940 - accuracy: 0.9381 - val_loss: 0.3219 - val_accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(32, 32, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.9118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32192978262901306, 0.9117570519447327]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(val_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG\n",
      "(32, 32)\n",
      "RGB\n"
     ]
    }
   ],
   "source": [
    "# load and show an image with Pillow\n",
    "from PIL import Image\n",
    "# Open the image form working directory\n",
    "image = Image.open('data/archive/00_00_00/00_00_00_0000.png')\n",
    "# summarize some details about the image\n",
    "print(image.format)\n",
    "print(image.size)\n",
    "print(image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'PIL.PngImagePlugin.PngImageFile'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ccfbcbe759c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 991\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    992\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'PIL.PngImagePlugin.PngImageFile'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
