{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = [\"а\",\"б\",\"в\",\"г\",\"д\",\"е\",\"ё\",\"ж\",\"з\",\"и\",\"й\",\"к\",\"л\",\"м\",\"н\",\"о\",\n",
    "            \"п\",\"р\",\"с\",\"т\",\"у\",\"ф\",\"х\",\"ц\",\"ч\",\"ш\",\"щ\",\"ъ\",\"ы\",\"ь\",\"э\",\"ю\",\"я\"]\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['а',\n",
       "  'б',\n",
       "  'в',\n",
       "  'г',\n",
       "  'д',\n",
       "  'е',\n",
       "  'ё',\n",
       "  'ж',\n",
       "  'з',\n",
       "  'и',\n",
       "  'й',\n",
       "  'к',\n",
       "  'л',\n",
       "  'м',\n",
       "  'н',\n",
       "  'о',\n",
       "  'п',\n",
       "  'р',\n",
       "  'с',\n",
       "  'т',\n",
       "  'у',\n",
       "  'ф',\n",
       "  'х',\n",
       "  'ц',\n",
       "  'ч',\n",
       "  'ш',\n",
       "  'щ',\n",
       "  'ъ',\n",
       "  'ы',\n",
       "  'ь',\n",
       "  'э',\n",
       "  'ю',\n",
       "  'я',\n",
       "  'А',\n",
       "  'Б',\n",
       "  'В',\n",
       "  'Г',\n",
       "  'Д',\n",
       "  'Е',\n",
       "  'Ё',\n",
       "  'Ж',\n",
       "  'З',\n",
       "  'И',\n",
       "  'Й',\n",
       "  'К',\n",
       "  'Л',\n",
       "  'М',\n",
       "  'Н',\n",
       "  'О',\n",
       "  'П',\n",
       "  'Р',\n",
       "  'С',\n",
       "  'Т',\n",
       "  'У',\n",
       "  'Ф',\n",
       "  'Х',\n",
       "  'Ц',\n",
       "  'Ч',\n",
       "  'Ш',\n",
       "  'Щ',\n",
       "  'Ъ',\n",
       "  'Ы',\n",
       "  'Ь',\n",
       "  'Э',\n",
       "  'Ю',\n",
       "  'Я'],\n",
       " 66)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = alphabet + [x.upper() for x in alphabet]\n",
    "alphabet, len(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mv  -v ~/Downloads/* ~/Videos/\n",
    "\n",
    "It will move all the files and folders from Downloads folder to Videos folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_20_00',\n",
       " '01_14_00',\n",
       " '01_04_00',\n",
       " '01_30_00',\n",
       " '01_10_00',\n",
       " '01_24_00',\n",
       " '01_00_00',\n",
       " '01_11_00',\n",
       " '01_25_00',\n",
       " '01_01_00',\n",
       " '01_21_00',\n",
       " '01_15_00',\n",
       " '01_05_00',\n",
       " '01_31_00',\n",
       " '00_24_00',\n",
       " '00_10_00',\n",
       " '00_00_00',\n",
       " '00_14_00',\n",
       " '00_20_00',\n",
       " '00_30_00',\n",
       " '00_04_00',\n",
       " '00_15_00',\n",
       " '00_21_00',\n",
       " '00_31_00',\n",
       " '00_05_00',\n",
       " '00_25_00',\n",
       " '00_11_00',\n",
       " '00_01_00',\n",
       " '01_18_00',\n",
       " '00_16_00',\n",
       " '00_22_00',\n",
       " '00_32_00',\n",
       " '00_06_00',\n",
       " '01_08_00',\n",
       " '01_28_00',\n",
       " '00_26_00',\n",
       " '00_12_00',\n",
       " '00_02_00',\n",
       " '01_29_00',\n",
       " '00_27_00',\n",
       " '00_13_00',\n",
       " '00_03_00',\n",
       " '01_19_00',\n",
       " '00_17_00',\n",
       " '00_23_00',\n",
       " '00_07_00',\n",
       " '01_09_00',\n",
       " '01_12_00',\n",
       " '00_28_00',\n",
       " '01_26_00',\n",
       " '01_02_00',\n",
       " '01_22_00',\n",
       " '00_18_00',\n",
       " '01_16_00',\n",
       " '01_06_00',\n",
       " '00_08_00',\n",
       " '01_32_00',\n",
       " '01_23_00',\n",
       " '00_19_00',\n",
       " '01_17_00',\n",
       " '01_07_00',\n",
       " '00_09_00',\n",
       " '01_13_00',\n",
       " '00_29_00',\n",
       " '01_27_00',\n",
       " '01_03_00']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = 'data/archive/00_00_00/00_00_00'\n",
    "pths = os.listdir('data/archive')\n",
    "pths.remove('.DS_Store')\n",
    "pths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mv  -v data/archive/01_20_00/01_20_00/* data/archive/01_20_00/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "f\"mv  -v {paths[i]}/* {paths[0][:paths[0].rfind('/')]}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/archive/01_20_00/01_20_00',\n",
       " 'data/archive/01_14_00/01_14_00',\n",
       " 'data/archive/01_04_00/01_04_00',\n",
       " 'data/archive/01_30_00/01_30_00',\n",
       " 'data/archive/01_10_00/01_10_00',\n",
       " 'data/archive/01_24_00/01_24_00',\n",
       " 'data/archive/01_00_00/01_00_00',\n",
       " 'data/archive/01_11_00/01_11_00',\n",
       " 'data/archive/01_25_00/01_25_00',\n",
       " 'data/archive/01_01_00/01_01_00',\n",
       " 'data/archive/01_21_00/01_21_00',\n",
       " 'data/archive/01_15_00/01_15_00',\n",
       " 'data/archive/01_05_00/01_05_00',\n",
       " 'data/archive/01_31_00/01_31_00',\n",
       " 'data/archive/00_24_00/00_24_00',\n",
       " 'data/archive/00_10_00/00_10_00',\n",
       " 'data/archive/00_00_00/00_00_00',\n",
       " 'data/archive/00_14_00/00_14_00',\n",
       " 'data/archive/00_20_00/00_20_00',\n",
       " 'data/archive/00_30_00/00_30_00',\n",
       " 'data/archive/00_04_00/00_04_00',\n",
       " 'data/archive/00_15_00/00_15_00',\n",
       " 'data/archive/00_21_00/00_21_00',\n",
       " 'data/archive/00_31_00/00_31_00',\n",
       " 'data/archive/00_05_00/00_05_00',\n",
       " 'data/archive/00_25_00/00_25_00',\n",
       " 'data/archive/00_11_00/00_11_00',\n",
       " 'data/archive/00_01_00/00_01_00',\n",
       " 'data/archive/01_18_00/01_18_00',\n",
       " 'data/archive/00_16_00/00_16_00',\n",
       " 'data/archive/00_22_00/00_22_00',\n",
       " 'data/archive/00_32_00/00_32_00',\n",
       " 'data/archive/00_06_00/00_06_00',\n",
       " 'data/archive/01_08_00/01_08_00',\n",
       " 'data/archive/01_28_00/01_28_00',\n",
       " 'data/archive/00_26_00/00_26_00',\n",
       " 'data/archive/00_12_00/00_12_00',\n",
       " 'data/archive/00_02_00/00_02_00',\n",
       " 'data/archive/01_29_00/01_29_00',\n",
       " 'data/archive/00_27_00/00_27_00',\n",
       " 'data/archive/00_13_00/00_13_00',\n",
       " 'data/archive/00_03_00/00_03_00',\n",
       " 'data/archive/01_19_00/01_19_00',\n",
       " 'data/archive/00_17_00/00_17_00',\n",
       " 'data/archive/00_23_00/00_23_00',\n",
       " 'data/archive/00_07_00/00_07_00',\n",
       " 'data/archive/01_09_00/01_09_00',\n",
       " 'data/archive/01_12_00/01_12_00',\n",
       " 'data/archive/00_28_00/00_28_00',\n",
       " 'data/archive/01_26_00/01_26_00',\n",
       " 'data/archive/01_02_00/01_02_00',\n",
       " 'data/archive/01_22_00/01_22_00',\n",
       " 'data/archive/00_18_00/00_18_00',\n",
       " 'data/archive/01_16_00/01_16_00',\n",
       " 'data/archive/01_06_00/01_06_00',\n",
       " 'data/archive/00_08_00/00_08_00',\n",
       " 'data/archive/01_32_00/01_32_00',\n",
       " 'data/archive/01_23_00/01_23_00',\n",
       " 'data/archive/00_19_00/00_19_00',\n",
       " 'data/archive/01_17_00/01_17_00',\n",
       " 'data/archive/01_07_00/01_07_00',\n",
       " 'data/archive/00_09_00/00_09_00',\n",
       " 'data/archive/01_13_00/01_13_00',\n",
       " 'data/archive/00_29_00/00_29_00',\n",
       " 'data/archive/01_27_00/01_27_00',\n",
       " 'data/archive/01_03_00/01_03_00']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for path in pths:\n",
    "    paths.append('data/archive/'+path+'/'+path)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('move.sh', 'w') as file:\n",
    "    file.write('#!/bin/bash\\n')\n",
    "    for i in range(len(paths)):\n",
    "        file.write(f\"mv  -v {paths[i]}/* {paths[i][:paths[i].rfind('/')]}/\\n\")\n",
    "        file.write(f\"rm -r {paths[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/archive/00_00_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "image = PIL.Image.open(\"/Users/makarbaderko/Downloads/archive/00_00_00/00_00_00/00_00_00_0000.png\")\n",
    "width, height = image.size\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57627 files belonging to 66 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    './data/archive', labels='inferred', label_mode='int',\n",
    "    class_names=None, color_mode='rgb', batch_size=32, image_size=(32,\n",
    "    32), shuffle=False, seed=None, validation_split=None, subset=None,\n",
    "    interpolation='bilinear', follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57627 files belonging to 66 classes.\n",
      "Using 46102 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    './data/archive', labels='inferred', label_mode='int',\n",
    "     color_mode='rgb', batch_size=32, image_size=(32,\n",
    "    32), seed=42, validation_split=0.2, subset='training',\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57627 files belonging to 66 classes.\n",
      "Using 11525 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    './data/archive', labels='inferred', label_mode='int',\n",
    "     color_mode='rgb', batch_size=32, image_size=(32,\n",
    "    32), seed=42, validation_split=0.2, subset='validation',\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_names = alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds.class_names = alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(alphabet)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(32, 32, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7ffdb3cd36a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7ffdb3cd36a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1440/1441 [============================>.] - ETA: 0s - loss: 2.4686 - accuracy: 0.3810WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7ffd95f59ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7ffd95f59ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1441/1441 [==============================] - 29s 19ms/step - loss: 2.4677 - accuracy: 0.3812 - val_loss: 1.1436 - val_accuracy: 0.6803\n",
      "Epoch 2/10\n",
      "1441/1441 [==============================] - 30s 21ms/step - loss: 0.8768 - accuracy: 0.7544 - val_loss: 0.7192 - val_accuracy: 0.7911\n",
      "Epoch 3/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.5996 - accuracy: 0.8265 - val_loss: 0.5946 - val_accuracy: 0.8269\n",
      "Epoch 4/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.4531 - accuracy: 0.8674 - val_loss: 0.4744 - val_accuracy: 0.8587\n",
      "Epoch 5/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.3750 - accuracy: 0.8872 - val_loss: 0.4277 - val_accuracy: 0.8787\n",
      "Epoch 6/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.3168 - accuracy: 0.9031 - val_loss: 0.3680 - val_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.2733 - accuracy: 0.9161 - val_loss: 0.4226 - val_accuracy: 0.8778\n",
      "Epoch 8/10\n",
      "1441/1441 [==============================] - 27s 19ms/step - loss: 0.2400 - accuracy: 0.9254 - val_loss: 0.3447 - val_accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "1441/1441 [==============================] - 34s 23ms/step - loss: 0.2146 - accuracy: 0.9329 - val_loss: 0.3448 - val_accuracy: 0.9040\n",
      "Epoch 10/10\n",
      "1441/1441 [==============================] - 31s 22ms/step - loss: 0.1940 - accuracy: 0.9381 - val_loss: 0.3219 - val_accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(32, 32, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.9118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32192978262901306, 0.9117570519447327]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(val_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG\n",
      "(32, 32)\n",
      "RGB\n"
     ]
    }
   ],
   "source": [
    "# load and show an image with Pillow\n",
    "from PIL import Image\n",
    "# Open the image form working directory\n",
    "image = Image.open('data/archive/00_02_00/00_02_00_0000.png')\n",
    "# summarize some details about the image\n",
    "print(image.format)\n",
    "print(image.size)\n",
    "print(image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = model_2.predict(tf.expand_dims(arr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet[l.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Downloading tensorflowjs-3.13.0-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.34.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.13.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (12.0.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.35.1)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.10.0.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.23.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
      "Requirement already satisfied: cached-property in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow<3,>=2.1.0->tensorflowjs) (51.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.21.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2020.6.20)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Collecting tensorflow-hub<0.13,>=0.7.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.0)\n",
      "Installing collected packages: tensorflow-hub, tensorflowjs\n",
      "Successfully installed tensorflow-hub-0.12.0 tensorflowjs-3.13.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, './tfjs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 66)                8514      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,298\n",
      "Trainable params: 163,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!tensorflowjs_converter --input_format keras model.h5 model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(32, 32, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(66)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f8352210e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f8352210e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f83524c3f28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f83524c3f28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /var/folders/l4/18w037ln441cmfkn2_frnffc0000gn/T/tmpqbd_rtt9/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "656696"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'TFLiteKerasModelConverterV2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-55330257e081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'TFLiteKerasModelConverterV2'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
